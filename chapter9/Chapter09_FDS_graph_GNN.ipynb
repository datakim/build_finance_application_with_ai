{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8deeab50-5dc4-424e-9540-7b8d7df47805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'fraud_transactions.csv' loaded successfully.\n",
      "--------------------------------------------------\n",
      "First few rows of the transaction dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_time</th>\n",
       "      <th>ip</th>\n",
       "      <th>device_id</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>credit_card_number</th>\n",
       "      <th>order_item</th>\n",
       "      <th>amount</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05987d33-9bcd-4455-9d7c-2f043b007b10</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>219.20.206.172</td>\n",
       "      <td>8efe3214-ea7f-47ef-bb30-716e28f02600</td>\n",
       "      <td>(527)638-2221x33874</td>\n",
       "      <td>4908554227138584</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>201631</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>013414be-3e37-48fb-aab2-5f42a4933db8</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>219.20.206.172</td>\n",
       "      <td>8efe3214-ea7f-47ef-bb30-716e28f02600</td>\n",
       "      <td>(527)638-2221x33874</td>\n",
       "      <td>4908554227138584</td>\n",
       "      <td>Kids Products</td>\n",
       "      <td>281063</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c6d1eed6-2c40-44f0-8a6f-fec0f8f7a83b</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-12</td>\n",
       "      <td>219.20.206.172</td>\n",
       "      <td>8efe3214-ea7f-47ef-bb30-716e28f02600</td>\n",
       "      <td>(527)638-2221x33874</td>\n",
       "      <td>4908554227138584</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>279119</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90321501-3b4f-4cd3-92e9-ae1531b6b705</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>219.20.206.172</td>\n",
       "      <td>8efe3214-ea7f-47ef-bb30-716e28f02600</td>\n",
       "      <td>(527)638-2221x33874</td>\n",
       "      <td>4908554227138584</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>253019</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2169fe4b-772a-45ef-9478-dbc48ee0e331</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>219.20.206.172</td>\n",
       "      <td>8efe3214-ea7f-47ef-bb30-716e28f02600</td>\n",
       "      <td>(527)638-2221x33874</td>\n",
       "      <td>4908554227138584</td>\n",
       "      <td>Food</td>\n",
       "      <td>170733</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         transaction_id  user_id transaction_time  \\\n",
       "0  05987d33-9bcd-4455-9d7c-2f043b007b10        0       2024-05-07   \n",
       "1  013414be-3e37-48fb-aab2-5f42a4933db8        0       2024-05-09   \n",
       "2  c6d1eed6-2c40-44f0-8a6f-fec0f8f7a83b        0       2024-05-12   \n",
       "3  90321501-3b4f-4cd3-92e9-ae1531b6b705        0       2024-05-01   \n",
       "4  2169fe4b-772a-45ef-9478-dbc48ee0e331        0       2024-05-09   \n",
       "\n",
       "               ip                             device_id         phone_number  \\\n",
       "0  219.20.206.172  8efe3214-ea7f-47ef-bb30-716e28f02600  (527)638-2221x33874   \n",
       "1  219.20.206.172  8efe3214-ea7f-47ef-bb30-716e28f02600  (527)638-2221x33874   \n",
       "2  219.20.206.172  8efe3214-ea7f-47ef-bb30-716e28f02600  (527)638-2221x33874   \n",
       "3  219.20.206.172  8efe3214-ea7f-47ef-bb30-716e28f02600  (527)638-2221x33874   \n",
       "4  219.20.206.172  8efe3214-ea7f-47ef-bb30-716e28f02600  (527)638-2221x33874   \n",
       "\n",
       "   credit_card_number     order_item  amount  is_fraud  \n",
       "0    4908554227138584    Accessories  201631     False  \n",
       "1    4908554227138584  Kids Products  281063     False  \n",
       "2    4908554227138584      Cosmetics  279119     False  \n",
       "3    4908554227138584    Accessories  253019     False  \n",
       "4    4908554227138584           Food  170733     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Dataset Shape: (14813, 10)\n",
      "--------------------------------------------------\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14813 entries, 0 to 14812\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   transaction_id      14813 non-null  object\n",
      " 1   user_id             14813 non-null  int64 \n",
      " 2   transaction_time    14813 non-null  object\n",
      " 3   ip                  14813 non-null  object\n",
      " 4   device_id           14813 non-null  object\n",
      " 5   phone_number        14813 non-null  object\n",
      " 6   credit_card_number  14813 non-null  int64 \n",
      " 7   order_item          14813 non-null  object\n",
      " 8   amount              14813 non-null  int64 \n",
      " 9   is_fraud            14813 non-null  bool  \n",
      "dtypes: bool(1), int64(3), object(6)\n",
      "memory usage: 1.0+ MB\n",
      "--------------------------------------------------\n",
      "Distribution of 'is_fraud' label:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proportion</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.982245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.017755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Proportion  proportion\n",
       "0       False    0.982245\n",
       "1        True    0.017755"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "# Ensure other common libraries like numpy, matplotlib, seaborn are imported\n",
    "# in a common cell at the beginning of the notebook, as per previous discussions.\n",
    "# For NetworkX, it will be imported when first used.\n",
    "\n",
    "# Define the path to our custom transaction dataset\n",
    "TRANSACTION_DATA_PATH = \"fraud_transactions.csv\" \n",
    "\n",
    "try:\n",
    "    transactions_df = pd.read_csv(TRANSACTION_DATA_PATH)\n",
    "    print(f\"'{TRANSACTION_DATA_PATH}' loaded successfully.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"First few rows of the transaction dataset:\")\n",
    "    display(transactions_df.head()) # Display more rows if needed, e.g., head(10)\n",
    "    print(\"\\n--------------------------------------------------\")\n",
    "    print(f\"Dataset Shape: {transactions_df.shape}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    # Basic info about data types and missing values\n",
    "    print(\"Dataset Info:\")\n",
    "    transactions_df.info()\n",
    "    print(\"--------------------------------------------------\")\n",
    "    if 'is_fraud' in transactions_df.columns:\n",
    "        print(\"Distribution of 'is_fraud' label:\")\n",
    "        display(transactions_df['is_fraud'].value_counts(normalize=True).reset_index().rename(\n",
    "            columns={'index': 'Is_Fraud', 'is_fraud': 'Proportion'}\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Note: 'is_fraud' column not found. Analysis will proceed without it for now.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{TRANSACTION_DATA_PATH}' was not found.\")\n",
    "    print(\"Please ensure you have this file from the book's GitHub repository (chapter09/data folder)\")\n",
    "    print(\"and that it is in the correct path relative to your Jupyter Notebook.\")\n",
    "    transactions_df = None # Set to None if loading fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f84cf3d-2d3e-461f-9595-ed9c49485ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Fast GNN Fraud Detection Demo\n",
      "===================================\n",
      "ðŸ“Š Total data: 14813 transactions\n",
      "ðŸ“Š Using full dataset\n",
      "   ðŸ“Š Creating node features...\n",
      "   ðŸ”— Computing connections...\n",
      "   âš¡ Creating sparse matrix...\n",
      "   Final nodes: 14813\n",
      "   Connections: 60142\n",
      "   Avg neighbors: 4.1\n",
      "\n",
      "ðŸŽ¯ Training GNN...\n",
      "   Epoch 0: Loss=1.111, Acc=0.982\n",
      "   Epoch 20: Loss=0.110, Acc=0.982\n",
      "   Epoch 40: Loss=0.106, Acc=0.982\n",
      "   Epoch 60: Loss=0.106, Acc=0.982\n",
      "   Epoch 80: Loss=0.098, Acc=0.982\n",
      "\n",
      "ðŸš¨ Most Suspicious Transactions TOP 5:\n",
      "   1. User:205, Amount:12168, Prob:0.492 (Actual: Fraud)\n",
      "   2. User:1550, Amount:19086, Prob:0.482 (Actual: Fraud)\n",
      "   3. User:163, Amount:57917, Prob:0.424 (Actual: Fraud)\n",
      "   4. User:2498, Amount:65591, Prob:0.414 (Actual: Fraud)\n",
      "   5. User:1364, Amount:134086, Prob:0.311 (Actual: Fraud)\n",
      "\n",
      "âœ… Optimized GNN analysis complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(FraudGNN(\n",
       "   (conv1): Linear(in_features=3, out_features=16, bias=True)\n",
       "   (conv2): Linear(in_features=16, out_features=16, bias=True)\n",
       "   (classifier): Linear(in_features=16, out_features=2, bias=True)\n",
       " ),\n",
       " tensor([0.0022, 0.0016, 0.0016,  ..., 0.0173, 0.0249, 0.0127]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimized GNN Demo - Fast Graph Generation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Simple GNN Model\n",
    "class FraudGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32):\n",
    "        super(FraudGNN, self).__init__()\n",
    "        self.conv1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conv2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)  # Normal/Fraud\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        # First GNN layer: Aggregate neighbor information\n",
    "        h1 = torch.relu(self.conv1(x))\n",
    "        h1_agg = torch.mm(adj, h1)  # Average neighbors' information\n",
    "        h1 = h1 + h1_agg\n",
    "        \n",
    "        # Second GNN layer\n",
    "        h2 = torch.relu(self.conv2(h1))\n",
    "        h2_agg = torch.mm(adj, h2)\n",
    "        h2 = h2 + h2_agg\n",
    "        \n",
    "        # Classification\n",
    "        out = self.classifier(h2)\n",
    "        return out\n",
    "\n",
    "def create_fast_graph(df, max_connections=50):\n",
    "    \"\"\"Fast graph generation using vectorized operations\"\"\"\n",
    "    print(\"   ðŸ“Š Creating node features...\")\n",
    "    n = len(df)\n",
    "    \n",
    "    # Node features: [amount, hour, weekday] - vectorized\n",
    "    times = pd.to_datetime(df['transaction_time'])\n",
    "    features = np.column_stack([\n",
    "        df['amount'].values / 1000,\n",
    "        times.dt.hour / 24,\n",
    "        times.dt.weekday / 7\n",
    "    ])\n",
    "    \n",
    "    print(\"   ðŸ”— Computing connections...\")\n",
    "    # Efficient adjacency matrix generation\n",
    "    row_indices = []\n",
    "    col_indices = []\n",
    "    \n",
    "    # Connect transactions with same user_id\n",
    "    for user_id in df['user_id'].unique():\n",
    "        user_mask = df['user_id'] == user_id\n",
    "        user_indices = np.where(user_mask)[0]\n",
    "        \n",
    "        if len(user_indices) > 1:\n",
    "            # Generate all combinations (excluding self)\n",
    "            for i in user_indices:\n",
    "                for j in user_indices:\n",
    "                    if i != j:\n",
    "                        row_indices.append(i)\n",
    "                        col_indices.append(j)\n",
    "    \n",
    "    # Connect transactions with same device_id\n",
    "    for device_id in df['device_id'].unique():\n",
    "        device_mask = df['device_id'] == device_id\n",
    "        device_indices = np.where(device_mask)[0]\n",
    "        \n",
    "        if len(device_indices) > 1:\n",
    "            for i in device_indices:\n",
    "                for j in device_indices:\n",
    "                    if i != j:\n",
    "                        row_indices.append(i)\n",
    "                        col_indices.append(j)\n",
    "    \n",
    "    print(\"   âš¡ Creating sparse matrix...\")\n",
    "    # Create sparse matrix (memory efficient)\n",
    "    if row_indices:\n",
    "        data = np.ones(len(row_indices))\n",
    "        adj_sparse = csr_matrix((data, (row_indices, col_indices)), shape=(n, n))\n",
    "        \n",
    "        # Normalization\n",
    "        row_sum = np.array(adj_sparse.sum(axis=1)).flatten()\n",
    "        row_sum[row_sum == 0] = 1\n",
    "        adj_sparse = adj_sparse.multiply(1.0 / row_sum.reshape(-1, 1))\n",
    "        \n",
    "        # Convert to dense matrix (only for small data)\n",
    "        if n < 1000:\n",
    "            adj_matrix = adj_sparse.toarray()\n",
    "        else:\n",
    "            # Keep sparse matrix for large data\n",
    "            adj_matrix = adj_sparse\n",
    "    else:\n",
    "        adj_matrix = np.eye(n)  # Identity matrix if no connections\n",
    "    \n",
    "    return features, adj_matrix\n",
    "\n",
    "def run_fast_gnn_demo():\n",
    "    \"\"\"Run optimized GNN demo\"\"\"\n",
    "    print(\"ðŸš€ Fast GNN Fraud Detection Demo\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    if 'transactions_df' not in globals():\n",
    "        print(\"âŒ transactions_df not found!\")\n",
    "        return\n",
    "    \n",
    "    df = transactions_df\n",
    "    print(f\"ðŸ“Š Total data: {len(df)} transactions\")\n",
    "    \n",
    "    # 1. Use full dataset (no sampling)\n",
    "    print(\"ðŸ“Š Using full dataset\")\n",
    "    features, adj_matrix = create_fast_graph(df)\n",
    "    \n",
    "    print(f\"   Final nodes: {len(features)}\")\n",
    "    \n",
    "    # Connection information\n",
    "    if hasattr(adj_matrix, 'nnz'):  # Sparse matrix\n",
    "        print(f\"   Connections: {adj_matrix.nnz}\")\n",
    "        print(f\"   Avg neighbors: {adj_matrix.nnz / len(features):.1f}\")\n",
    "        # Convert sparse to dense matrix\n",
    "        adj_matrix = adj_matrix.toarray()\n",
    "    else:\n",
    "        print(f\"   Connections: {(adj_matrix > 0).sum()}\")\n",
    "        print(f\"   Avg neighbors: {(adj_matrix > 0).sum(axis=1).mean():.1f}\")\n",
    "    \n",
    "    # 2. Convert to tensors\n",
    "    X = torch.FloatTensor(features)\n",
    "    A = torch.FloatTensor(adj_matrix)\n",
    "    \n",
    "    # 3. Create model\n",
    "    model = FraudGNN(input_dim=3, hidden_dim=16)\n",
    "    \n",
    "    # 4. Train if labels exist, otherwise inference only\n",
    "    if 'is_fraud' in df.columns:\n",
    "        print(\"\\nðŸŽ¯ Training GNN...\")\n",
    "        y = torch.LongTensor(df['is_fraud'].values)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Improved training (more epochs and learning rate scheduling)\n",
    "        best_loss = float('inf')\n",
    "        patience = 0\n",
    "        \n",
    "        for epoch in range(100):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X, A)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch % 20 == 0:\n",
    "                acc = (outputs.argmax(1) == y).float().mean()\n",
    "                print(f\"   Epoch {epoch}: Loss={loss:.3f}, Acc={acc:.3f}\")\n",
    "                \n",
    "                # Early stopping check\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    patience = 0\n",
    "                else:\n",
    "                    patience += 1\n",
    "                    if patience > 3 and epoch > 40:\n",
    "                        print(f\"   Early stopping at epoch {epoch}\")\n",
    "                        break\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nðŸ”® GNN inference mode...\")\n",
    "    \n",
    "    # 5. Results analysis\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X, A)\n",
    "        fraud_probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "    \n",
    "    # Top suspicious transactions (TOP 5)\n",
    "    top_indices = fraud_probs.argsort(descending=True)[:5]\n",
    "    print(f\"\\nðŸš¨ Most Suspicious Transactions TOP 5:\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        idx = int(idx)  # Convert tensor index to integer\n",
    "        row = df.iloc[idx]\n",
    "        prob = fraud_probs[idx]\n",
    "        actual = f\" (Actual: {'Fraud' if 'is_fraud' in df.columns and row['is_fraud'] else 'Normal'})\" if 'is_fraud' in df.columns else \"\"\n",
    "        print(f\"   {i+1}. User:{row['user_id']}, Amount:{row['amount']}, Prob:{prob:.3f}{actual}\")\n",
    "    \n",
    "    print(f\"\\nâœ… Optimized GNN analysis complete!\")\n",
    "    \n",
    "    return model, fraud_probs\n",
    "\n",
    "# Run\n",
    "run_fast_gnn_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7061d-cdc0-4288-a2d3-12f65e2e3d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89a4d2-c84e-443b-a116-97400d94c71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
